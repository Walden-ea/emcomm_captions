{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0981012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08650be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ds = load_from_disk(\"../../../datasets/coco_val_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742cd04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print([torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms\n",
    "\n",
    "# Load ResNet model and set to eval mode\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet.eval()\n",
    "\n",
    "# Define image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "def image_to_features(example):\n",
    "    # Convert PIL image to tensor and preprocess\n",
    "    image = example[\"image\"]\n",
    "    input_tensor = preprocess(image).unsqueeze(0).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resnet.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        features = resnet(input_tensor)\n",
    "    return {\"image_tensor\": features.cpu().squeeze().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef402af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = original_ds.map(\n",
    "    lambda example: {\n",
    "        \"captions\": example[\"captions\"],\n",
    "        \"features\": torch.tensor(image_to_features(example)[\"image_tensor\"])\n",
    "    },\n",
    "    remove_columns=[col for col in original_ds.column_names if col not in [\"captions\"]],\n",
    "    # num_proc=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds.save_to_disk(\"../../../datasets/coco_val_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ef038",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_ds[0]['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d5145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[350]['captions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac2c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emcomm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
