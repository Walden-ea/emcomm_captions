{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4094ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elena/miniconda/envs/emcomm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/elena/miniconda/envs/emcomm/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/elena/miniconda/envs/emcomm/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "# from datasets import load_from_disk\n",
    "from collections import namedtuple\n",
    "from features import VectorsLoader\n",
    "import torch\n",
    "from archs import Sender, Receiver\n",
    "import egg.core as core\n",
    "import torch.nn.functional as F\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b97e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers=2, pad_id=None):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: [B, T]\n",
    "        embedded = self.emb(src)               # [B, T, emb_dim]\n",
    "        outputs, (h, c) = self.rnn(embedded)  # outputs ignored for vanilla seq2seq\n",
    "        return h, c                            # [num_layers, B, hid_dim]\n",
    "\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers=2, pad_id=None):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, vocab_size)\n",
    "\n",
    "    def forward(self, tgt, h, c):\n",
    "        # tgt: [B, T] (with <sos> prepended)\n",
    "        embedded = self.emb(tgt)               # [B, T, emb_dim]\n",
    "        outputs, (h, c) = self.rnn(embedded, (h, c))\n",
    "        logits = self.fc(outputs)              # [B, T, vocab_size]\n",
    "        return logits, h, c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894deb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "tgt_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tgt_pad_id = tgt_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096c62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "PAD_ID = 70\n",
    "\n",
    "def collate(batch):\n",
    "    src = [torch.tensor(b['message_truncated'], dtype=torch.long) for b in batch]\n",
    "    src = pad_sequence(\n",
    "        src,\n",
    "        batch_first=True,\n",
    "        padding_value=PAD_ID\n",
    "    )\n",
    "\n",
    "    tgt = tgt_tokenizer(\n",
    "        [b['captions'][0] for b in batch],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43f3cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d243d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    vocab_size=70+1,  # +1 for PAD\n",
    "    emb_dim=256,\n",
    "    hid_dim=512,\n",
    "    pad_id=PAD_ID\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    vocab_size=len(tgt_tokenizer.vocab),\n",
    "    emb_dim=256,\n",
    "    hid_dim=512,\n",
    "    pad_id=tgt_pad_id\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f77a03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Column'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_disk(\"../../../datasets/coco_train_msg_captions\")\n",
    "val_dataset = load_from_disk(\"../../../datasets/coco_val_msg_captions\")\n",
    "\n",
    "print(type(dataset['message_truncated']))\n",
    "print(type(dataset['message_truncated'][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e914aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d8030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (emb): Embedding(71, 256, padding_idx=70)\n",
       "  (rnn): LSTM(256, 512, num_layers=2, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0948291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (emb): Embedding(30522, 256, padding_idx=0)\n",
       "  (rnn): LSTM(256, 512, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_pad_id)\n",
    "enc_opt = torch.optim.Adam(encoder.parameters(), lr=1e-2)\n",
    "dec_opt = torch.optim.Adam(decoder.parameters(), lr=1e-2)\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6cc4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c9d33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared wandb config: {'device': 'cuda', 'pad_id': 70, 'tgt_pad_id': 0, 'enc_vocab_size': 71, 'dec_vocab_size': 30522, 'emb_dim': 256, 'hid_dim': 512, 'enc_num_layers': 2, 'dec_num_layers': 2, 'encoder_pad_idx': 70, 'decoder_pad_idx': 0, 'batch_size': 512, 'lr_enc': 0.01, 'lr_dec': 0.01, 'optim_enc': 'Adam', 'optim_dec': 'Adam', 'optim_enc_betas': (0.9, 0.999), 'optim_dec_betas': (0.9, 0.999), 'criterion': 'CrossEntropyLoss', 'dataset_len': 118287, 'dataset_features': ['coco_url', 'captions', 'image_id', 'features', 'message', 'message_truncated'], 'num_epochs': 10, 'tgt_tokenizer': 'bert-base-uncased'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meignatenko\u001b[0m (\u001b[33mnipg-elte\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/elena/emcomm/emcomm_captions/src/objects_game/wandb/run-20260206_194725-9vti9o4v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nipg-elte/EmComm-Caption-Translator/runs/9vti9o4v' target=\"_blank\">find_max_batch</a></strong> to <a href='https://wandb.ai/nipg-elte/EmComm-Caption-Translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nipg-elte/EmComm-Caption-Translator' target=\"_blank\">https://wandb.ai/nipg-elte/EmComm-Caption-Translator</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nipg-elte/EmComm-Caption-Translator/runs/9vti9o4v' target=\"_blank\">https://wandb.ai/nipg-elte/EmComm-Caption-Translator/runs/9vti9o4v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nipg-elte/EmComm-Caption-Translator/runs/9vti9o4v?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f3a134ee060>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "config = {\n",
    "    \"device\": str(device),\n",
    "    \"pad_id\": PAD_ID,\n",
    "    \"tgt_pad_id\": tgt_pad_id,\n",
    "    \"enc_vocab_size\": encoder.emb.num_embeddings,\n",
    "    \"dec_vocab_size\": decoder.emb.num_embeddings,\n",
    "    \"emb_dim\": encoder.emb.embedding_dim,\n",
    "    \"hid_dim\": encoder.rnn.hidden_size,\n",
    "    \"enc_num_layers\": encoder.rnn.num_layers,\n",
    "    \"dec_num_layers\": decoder.rnn.num_layers,\n",
    "    \"encoder_pad_idx\": encoder.emb.padding_idx,\n",
    "    \"decoder_pad_idx\": decoder.emb.padding_idx,\n",
    "    \"batch_size\": getattr(loader, \"batch_size\", None),\n",
    "    \"lr_enc\": enc_opt.param_groups[0][\"lr\"],\n",
    "    \"lr_dec\": dec_opt.param_groups[0][\"lr\"],\n",
    "    \"optim_enc\": type(enc_opt).__name__,\n",
    "    \"optim_dec\": type(dec_opt).__name__,\n",
    "    \"optim_enc_betas\": enc_opt.param_groups[0][\"betas\"],\n",
    "    \"optim_dec_betas\": dec_opt.param_groups[0][\"betas\"],\n",
    "    \"criterion\": type(criterion).__name__,\n",
    "    \"dataset_len\": len(dataset),\n",
    "    \"dataset_features\": list(dataset.features.keys()),\n",
    "    \"num_epochs\": num_epochs,\n",
    "    # \"sos_id\": sos_id,\n",
    "    # \"eos_id\": eos_id,\n",
    "    \"tgt_tokenizer\": getattr(tgt_tokenizer, \"name_or_path\", str(tgt_tokenizer)),\n",
    "}\n",
    "\n",
    "# ensure the subsequent wandb.init call will merge this config into the run\n",
    "_orig_wandb_init = wandb.init\n",
    "def _wandb_init_with_config(*args, **kwargs):\n",
    "    run = _orig_wandb_init(*args, **kwargs)\n",
    "    try:\n",
    "        wandb.config.update(config)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return run\n",
    "wandb.init = _wandb_init_with_config\n",
    "\n",
    "print(\"Prepared wandb config:\", config)\n",
    "# wandb.init(project=project, id=run_id, name=run_name, **kwargs)\n",
    "wandb.init(\n",
    "    project='EmComm-Caption-Translator',\n",
    "    name=\"find_max_batch\",\n",
    "    config={\n",
    "        \"emb_dim\": 256,\n",
    "        \"hid_dim\": 512,\n",
    "        # \"batch_size\": 32,\n",
    "        \"lr\": 3e-3,\n",
    "        \"num_epochs\": num_epochs,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f57d1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b3f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(encoder, decoder, loader, criterion, device):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for src, tgt in loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        h, c = encoder(src)\n",
    "        logits, _, _ = decoder(tgt[:, :-1], h, c)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt[:, 1:].reshape(-1)\n",
    "        )\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95e1f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10\n",
    "best_val_loss = float(\"inf\")\n",
    "patience_ctr = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fdb9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "sched_enc = ReduceLROnPlateau(enc_opt, mode=\"min\", factor=0.9, patience=20)\n",
    "sched_dec = ReduceLROnPlateau(dec_opt, mode=\"min\", factor=0.9, patience=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d25535e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, loader, criterion, device):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    refs, hyps = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            h, c = encoder(src)\n",
    "            logits, _, _ = decoder(tgt[:, :-1], h, c)\n",
    "\n",
    "            loss = criterion(\n",
    "                logits.reshape(-1, logits.size(-1)),\n",
    "                tgt[:, 1:].reshape(-1)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred = logits.argmax(-1)\n",
    "            hyps.extend(pred.tolist())\n",
    "            refs.extend(tgt[:, 1:].tolist())\n",
    "\n",
    "    bleu = sacrebleu.corpus_bleu(\n",
    "        [\" \".join(map(str, h)) for h in hyps],\n",
    "        [[\" \".join(map(str, r)) for r in refs]]\n",
    "    ).score\n",
    "\n",
    "    return total_loss / len(loader), bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb9def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2677c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|██████████| 232/232 [02:18<00:00,  1.68it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sacrebleu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m train_loss = total_loss / \u001b[38;5;28mlen\u001b[39m(loader)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# val_loss = evaluate(encoder, decoder, val_loader, criterion, device)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m val_loss, val_bleu = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m sched_enc.step(val_loss)\n\u001b[32m     44\u001b[39m sched_dec.step(val_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(encoder, decoder, loader, criterion, device)\u001b[39m\n\u001b[32m     22\u001b[39m         hyps.extend(pred.tolist())\n\u001b[32m     23\u001b[39m         refs.extend(tgt[:, \u001b[32m1\u001b[39m:].tolist())\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m bleu = \u001b[43msacrebleu\u001b[49m.corpus_bleu(\n\u001b[32m     26\u001b[39m     [\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, h)) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hyps],\n\u001b[32m     27\u001b[39m     [[\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, r)) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m refs]]\n\u001b[32m     28\u001b[39m ).score\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mlen\u001b[39m(loader), bleu\n",
      "\u001b[31mNameError\u001b[39m: name 'sacrebleu' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for src, tgt in tqdm(loader, desc=f\"epoch {epoch}\"):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        enc_opt.zero_grad()\n",
    "        dec_opt.zero_grad()\n",
    "\n",
    "        h, c = encoder(src)\n",
    "        logits, _, _ = decoder(tgt[:, :-1], h, c)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt[:, 1:].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        enc_opt.step()\n",
    "        dec_opt.step()\n",
    "        # sched_enc.step(lo\n",
    "        # ss)\n",
    "\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        wandb.log(\n",
    "            {\"train/batch_loss\": loss.item(),\n",
    "            \"lr/encoder\": enc_opt.param_groups[0][\"lr\"],\n",
    "            \"lr/decoder\": dec_opt.param_groups[0][\"lr\"],\n",
    "        })\n",
    "\n",
    "\n",
    "    train_loss = total_loss / len(loader)\n",
    "    # val_loss = evaluate(encoder, decoder, val_loader, criterion, device)\n",
    "    val_loss, val_bleu = evaluate(\n",
    "    encoder, decoder, val_loader, criterion, device\n",
    "    )\n",
    "    sched_enc.step(val_loss)\n",
    "    sched_dec.step(val_loss)\n",
    "\n",
    "    # wandb.log({\n",
    "    #     \"epoch\": epoch,\n",
    "    #     \"train/loss\": train_loss,\n",
    "    #     \"val/loss\": val_loss,\n",
    "    # })\n",
    "    wandb.log({\n",
    "    \"epoch\": epoch,\n",
    "    \"train/loss\": train_loss,\n",
    "    \"val/loss\": val_loss,\n",
    "    \"val/bleu\": val_bleu,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"epoch {epoch}: \"\n",
    "        f\"train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    # -------- early stopping --------\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_ctr = 0\n",
    "\n",
    "        # optional: save best model\n",
    "        torch.save({\n",
    "            \"encoder\": encoder.state_dict(),\n",
    "            \"decoder\": decoder.state_dict(),\n",
    "        }, \"best_model.pt\")\n",
    "\n",
    "        wandb.log({\"early_stop/best_val_loss\": best_val_loss})\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        wandb.log({\"early_stop/patience\": patience_ctr})\n",
    "\n",
    "        if patience_ctr >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56126e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_msg = torch.tensor([67, 44,  5, 23, 59, 65, 60, 61, 19, 14, 42, 67, 17, 10, 68, 18, 20, 43,\n",
    "          0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e3ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[67, 44,  5, 23, 59, 65, 60, 61, 19, 14, 42, 67, 17, 10, 68, 18, 20, 43,\n",
       "          0]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = [src_msg]\n",
    "src_padded = pad_sequence(\n",
    "    src,\n",
    "    batch_first=True,\n",
    "    padding_value=PAD_ID\n",
    ").to(device)\n",
    "src_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85941b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(encoder, decoder, src, max_len=50, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    src: [1, T_src] tensor, already padded\n",
    "    returns: list of token IDs\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    sos_id = tgt_tokenizer.cls_token_id\n",
    "    eos_id = tgt_tokenizer.sep_token_id\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h, c = encoder(src.to(device))\n",
    "\n",
    "        # first input to decoder\n",
    "        tgt_id = torch.tensor([[sos_id]], device=device)\n",
    "        output_ids = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            logits, h, c = decoder(tgt_id, h, c)           # [1, 1, vocab_size]\n",
    "            next_id = logits[:, -1, :].argmax(dim=-1)      # [1]\n",
    "            next_id_item = next_id.item()\n",
    "\n",
    "            if next_id_item == eos_id:\n",
    "                break\n",
    "\n",
    "            output_ids.append(next_id_item)\n",
    "            tgt_id = next_id.unsqueeze(0)                   # feed predicted token\n",
    "\n",
    "    return output_ids\n",
    "\n",
    "def decode_tokens(ids):\n",
    "    return tgt_tokenizer.decode(ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e03c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: a man riding a wave on top of a surfboard.\n"
     ]
    }
   ],
   "source": [
    "src_ind = [62, 42, 31, 63, 22, 60, 38, 13, 62, 56,  4, 37, 12, 35, 58, 59, 57, 65,\n",
    "         30, 62, 26, 51, 17, 24,  6, 37, 63, 50, 29, 40, 25, 50, 39,  9, 33, 19,\n",
    "         47, 11,  8,  0]\n",
    "src_example = torch.tensor([src_ind], device=device)\n",
    "translated_ids = greedy_decode(encoder, decoder, src_example, max_len=50, device=device)\n",
    "translated_text = decode_tokens(translated_ids)\n",
    "\n",
    "print(\"Translation:\", translated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emcomm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
